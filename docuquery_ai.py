# -*- coding: utf-8 -*-
"""DocuQuery-AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QRzxm3EXek4IKs3rf9Po8ZS4__aV3YQU
"""

# üß† DOCUQUERY AI ‚Äî SINGLE CODE FOR COLAB (WITH YOUTUBE + CACHING + PDFPLUMBER + TINYLLAMA)
# Supports: PDF, CSV, Image (OCR), Local Video, Audio, URL, YouTube
# One-click ‚Üí Gradio ‚Üí Deployable to HF Spaces

import os
import re
import tempfile
import subprocess
import sys
import hashlib

print("üì¶ Installing dependencies silently...")
os.system("pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
os.system("pip install -q transformers sentence-transformers faiss-cpu gradio PyPDF2 beautifulsoup4 requests pillow pytesseract pandas opencv-python pdfplumber")
os.system("pip install -q git+https://github.com/openai/whisper.git")
os.system("pip install -q yt-dlp")
os.system("apt-get install -y tesseract-ocr ffmpeg libgl1 libglib2.0-0 > /dev/null 2>&1")

print("‚úÖ Dependencies installed. Importing libraries...")

import torch
import faiss
import numpy as np
import pandas as pd
import pytesseract
from PIL import Image
from bs4 import BeautifulSoup
import requests
import whisper
import gradio as gr
from sentence_transformers import SentenceTransformer
from transformers import pipeline
import yt_dlp
import pdfplumber  # Better PDF extraction

print("üß† Loading models...")

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"‚û°Ô∏è  Using device: {device}")

embedder = SentenceTransformer('all-MiniLM-L6-v2', device=device)

# ‚úÖ Switch to TinyLlama-1.1B-Chat-v1.0
qa_pipeline = pipeline(
    "text-generation",
    model="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    device=0 if device == "cuda" else -1,
    torch_dtype=torch.bfloat16,  # Faster on GPU
    max_new_tokens=256,
    truncation=True
)

print("‚è≥ Loading Whisper (this may take 30-60 sec)...")
whisper_model = whisper.load_model("tiny.en", device=device)  # Even faster audio

print("‚úÖ Models ready!")

# ----------------------------
# FILE PROCESSING FUNCTIONS
# ----------------------------
def extract_text_from_pdf(file_path):
    """Use pdfplumber for better, faster PDF extraction."""
    text = ""
    try:
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                extracted = page.extract_text()
                if extracted:
                    text += extracted + "\n"
        return text.strip()
    except Exception as e:
        return f"‚ùå PDF extraction error: {str(e)}"

def extract_text_from_csv(file_path):
    try:
        df = pd.read_csv(file_path)
        return df.to_string()
    except Exception as e:
        return f"‚ùå CSV error: {str(e)}"

def extract_text_from_image(file_path):
    try:
        img = Image.open(file_path)
        text = pytesseract.image_to_string(img)
        return text.strip()
    except Exception as e:
        return f"‚ùå OCR error: {str(e)}"

def extract_audio_from_video(video_path, audio_path):
    command = f"ffmpeg -i '{video_path}' -ab 160k -ac 2 -ar 44100 -vn '{audio_path}' -y"
    subprocess.run(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

def extract_text_from_video(file_path):
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_audio:
        audio_path = tmp_audio.name
    try:
        extract_audio_from_video(file_path, audio_path)
        result = whisper_model.transcribe(audio_path)
        return result["text"].strip()
    except Exception as e:
        return f"‚ùå Video transcription error: {str(e)}"
    finally:
        if os.path.exists(audio_path):
            os.remove(audio_path)

def extract_text_from_audio(file_path):
    try:
        result = whisper_model.transcribe(file_path)
        return result["text"].strip()
    except Exception as e:
        return f"‚ùå Audio transcription error: {str(e)}"

def extract_text_from_youtube(url):
    """Download and transcribe YouTube audio."""
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_audio:
        audio_path = tmp_audio.name

    ydl_opts = {
        'format': 'bestaudio/best',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'wav',
            'preferredquality': '192',
        }],
        'outtmpl': audio_path.replace(".wav", ""),
        'quiet': True,
        'no_warnings': True,
        'noplaylist': True,
    }

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])
        result = whisper_model.transcribe(audio_path)
        os.remove(audio_path)
        return result["text"].strip()
    except Exception as e:
        if os.path.exists(audio_path):
            os.remove(audio_path)
        return f"‚ùå YouTube processing failed: {str(e)}"

def extract_text_from_url(url):
    if "youtube.com" in url or "youtu.be" in url:
        return extract_text_from_youtube(url)

    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        for script in soup(["script", "style"]):
            script.decompose()
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = '\n'.join(chunk for chunk in chunks if chunk)
        return text.strip()[:10000]
    except Exception as e:
        return f"‚ùå URL scraping error: {str(e)}"

def process_file(file_obj, file_type, url_text=None):
    try:
        if file_type == "url":
            return extract_text_from_url(url_text)
        elif file_type == "pdf":
            return extract_text_from_pdf(file_obj.name)
        elif file_type == "csv":
            return extract_text_from_csv(file_obj.name)
        elif file_type == "image":
            return extract_text_from_image(file_obj.name)
        elif file_type == "video":
            return extract_text_from_video(file_obj.name)
        elif file_type == "audio":
            return extract_text_from_audio(file_obj.name)
        else:
            return "‚ùå Unknown file type."
    except Exception as e:
        return f"‚ùå Processing error: {str(e)}"

# ----------------------------
# RAG SYSTEM WITH CACHING
# ----------------------------
class RAGSystem:
    def __init__(self, embedder):
        self.embedder = embedder
        self.index = None
        self.chunks = []
        self.chunk_size = 800
        self.cache = {}

    def get_file_hash(self, file_path):
        if not os.path.exists(file_path):
            return None
        hasher = hashlib.md5()
        with open(file_path, 'rb') as f:
            buf = f.read()
            hasher.update(buf)
        return hasher.hexdigest()

    def split_text(self, text):
        if not text or len(text.strip()) == 0:
            return []
        chunks = []
        current_chunk = ""
        for line in text.split('\n'):
            if len(current_chunk) + len(line) < self.chunk_size:
                current_chunk += line + "\n"
            else:
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                current_chunk = line + "\n"
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
        return chunks

    def add_document(self, text, identifier="default"):
        if identifier in self.cache:
            cached = self.cache[identifier]
            self.chunks = cached["chunks"]
            self.index = cached["index"]
            print(f"‚úÖ Loaded from cache: {identifier}")
            return

        chunks = self.split_text(text)
        if not chunks:
            return

        self.chunks = chunks
        embeddings = self.embedder.encode(chunks, convert_to_numpy=True, show_progress_bar=True)
        self.index = faiss.IndexFlatL2(embeddings.shape[1])
        self.index.add(embeddings.astype('float32'))

        self.cache[identifier] = {
            "chunks": self.chunks.copy(),
            "index": faiss.clone_index(self.index)
        }
        print(f"‚úÖ Cached document: {identifier}")

    def retrieve(self, query, top_k=3):
        if self.index is None or len(self.chunks) == 0:
            return []
        query_vec = self.embedder.encode([query], convert_to_numpy=True)
        distances, indices = self.index.search(query_vec.astype('float32'), min(top_k, len(self.chunks)))
        return [self.chunks[i] for i in indices[0] if i < len(self.chunks)]

    def query(self, question):
        context_chunks = self.retrieve(question)
        if not context_chunks:
            return "üîç No relevant context found."

        context = "\n\n".join(context_chunks)
        prompt = f"Answer based on the context below.\n\nContext:\n{context}\n\nQuestion: {question}\nAnswer:"

        try:
            output = qa_pipeline(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)
            return output[0]['generated_text']
        except Exception as e:
            return f"‚ùå Answer generation error: {str(e)}"

# Initialize RAG
rag_system = RAGSystem(embedder)

# ----------------------------
# GRADIO INTERFACE
# ----------------------------
def handle_upload(file_obj, url_text, question):
    if not question.strip():
        return "‚ö†Ô∏è Please enter a question."

    if not file_obj and not url_text:
        return "‚ö†Ô∏è Please upload a file or enter a URL."

    file_type = "url" if url_text else None
    identifier = url_text if url_text else "unknown"

    if file_obj:
        ext = os.path.splitext(file_obj.name)[1].lower()
        if ext in [".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp"]:
            file_type = "image"
        elif ext in [".mp4", ".avi", ".mov", ".mkv", ".webm"]:
            file_type = "video"
        elif ext in [".mp3", ".wav", ".flac", ".m4a"]:
            file_type = "audio"
        elif ext == ".pdf":
            file_type = "pdf"
            identifier = rag_system.get_file_hash(file_obj.name) or file_obj.name
        elif ext == ".csv":
            file_type = "csv"
            identifier = rag_system.get_file_hash(file_obj.name) or file_obj.name
        else:
            return f"‚ùå Unsupported file type: {ext}"

    print(f"üì• Processing: {identifier}")

    text = process_file(file_obj, file_type, url_text)
    if not text or "‚ùå" in text or len(text.strip()) < 10:
        return f"‚ùå Could not extract meaningful text. Preview: {text[:200]}..."

    rag_system.add_document(text, identifier=identifier)
    answer = rag_system.query(question)

    preview = text[:400] + "..." if len(text) > 400 else text
    return f"üìÑ Extracted Text Preview:\n{preview}\n\nüí¨ Answer:\n{answer}"

# Build UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ü§ñ DocuQuery AI ‚Äî Now with TinyLlama!")
    gr.Markdown("> Upload any file or URL ‚Üí Ask questions ‚Üí Get instant AI answers (faster & smarter!)")

    with gr.Row():
        file_input = gr.File(label="üìÇ Upload File (PDF, CSV, Image, Video, Audio)", type="filepath")
        url_input = gr.Textbox(label="üåê Enter URL (supports YouTube!)", placeholder="https://www.youtube.com/watch?v=...")
    question_input = gr.Textbox(label="‚ùì Ask a Question", placeholder="Summarize this in 2 sentences")
    output_box = gr.Textbox(label="üí° AI Answer", lines=10, max_lines=20)

    submit_btn = gr.Button("üöÄ Get Answer", variant="primary")
    submit_btn.click(
        fn=handle_upload,
        inputs=[file_input, url_input, question_input],
        outputs=output_box
    )

    gr.Markdown("""
    ### ‚úÖ Supported Inputs:
    - **üìÑ Documents**: `.pdf`, `.csv` ‚Üí Fast extraction with `pdfplumber`
    - **üñºÔ∏è Images**: `.jpg`, `.png` ‚Üí OCR via Tesseract
    - **üéµ Audio**: `.mp3`, `.wav` ‚Üí Whisper transcription
    - **üé• Video**: `.mp4`, `.avi` ‚Üí Audio extracted ‚Üí transcribed
    - **üåê Web**: Any public URL ‚Üí Scraped text
    - **‚ñ∂Ô∏è YouTube**: Full audio transcription from video links!
    - **‚ö° Caching**: Same file? No reprocessing!
    - **üöÄ TinyLlama**: Faster, more natural answers
    """)

# Launch
print("\nüöÄ Launching Gradio...")
print("üëâ Your public link will appear below in 10-30 seconds. Share it with anyone!")

demo.queue().launch(share=True, debug=False)

